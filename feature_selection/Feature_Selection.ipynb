{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential forward feature selection (SFFS)"
      ],
      "metadata": {
        "id": "vbvdLfxcmY8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mlxtend"
      ],
      "metadata": {
        "id": "nuAOqJYnngCv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "GY_sFmz4ibDU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn as sk\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.feature_selection import RFECV, RFE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, L = load_iris(return_X_y=True)\n",
        "X_train, X_test, L_train, L_test = train_test_split(X, L, test_size=0.3)"
      ],
      "metadata": {
        "id": "1XS9mc3zn62_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "GQbjSo85pdjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a145ac-1999-44e7-c5f8-ba792f34dd52"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "sfsl = SFS(knn, k_features=4, forward=True, floating=True, verbose=2, scoring='accuracy', cv=5)\n",
        "sfsl.fit(X_train, L_train)\n",
        "results = sfsl.subsets_\n",
        "print(results)"
      ],
      "metadata": {
        "id": "AtYcPI2JorLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c4500b-3c71-4ad7-b539-e5e163ab3161"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2024-03-19 10:01:46] Features: 1/4 -- score: 0.9428571428571428\n",
            "[2024-03-19 10:01:46] Features: 2/4 -- score: 0.9523809523809523\n",
            "[2024-03-19 10:01:46] Features: 3/4 -- score: 0.9523809523809523\n",
            "[2024-03-19 10:01:46] Features: 4/4 -- score: 0.9333333333333332"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: {'feature_idx': (2,), 'cv_scores': array([0.95238095, 0.95238095, 0.9047619 , 0.95238095, 0.95238095]), 'avg_score': 0.9428571428571428, 'feature_names': ('2',)}, 2: {'feature_idx': (2, 3), 'cv_scores': array([0.95238095, 0.95238095, 0.95238095, 0.95238095, 0.95238095]), 'avg_score': 0.9523809523809523, 'feature_names': ('2', '3')}, 3: {'feature_idx': (1, 2, 3), 'cv_scores': array([0.9047619 , 1.        , 0.95238095, 0.95238095, 0.95238095]), 'avg_score': 0.9523809523809523, 'feature_names': ('1', '2', '3')}, 4: {'feature_idx': (0, 1, 2, 3), 'cv_scores': array([0.9047619 , 0.95238095, 0.95238095, 0.9047619 , 0.95238095]), 'avg_score': 0.9333333333333332, 'feature_names': ('0', '1', '2', '3')}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM and feature selection with SFFS"
      ],
      "metadata": {
        "id": "ynSVfe3hsq5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without feature selection"
      ],
      "metadata": {
        "id": "kBFCY3cAtdvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, L = load_iris(return_X_y=True)\n",
        "X_train, X_test, L_train, L_test = train_test_split(X, L, test_size=0.3)\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit_transform(X_train)\n",
        "sc.fit(X_test)\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "print(kf.get_n_splits(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0iOybjasxdb",
        "outputId": "1f59da24-0906-4c7e-9d04-a4210d586945"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_svm_model(X, L):\n",
        "  ACC_WHOLE = []\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    L_train, L_test = L[train_index], L[test_index]\n",
        "    svm = SVC(kernel='linear')\n",
        "    svm.fit(X_train, L_train)\n",
        "    y_preds = svm.predict(X_test)\n",
        "    ACC_WHOLE.append(accuracy_score(L_test, y_preds))\n",
        "\n",
        "  print(f'svm support vectors shape = {svm.support_vectors_.shape}')\n",
        "  print(f'svm support vectors = {svm.n_support_}')\n",
        "\n",
        "  return ACC_WHOLE, np.mean(ACC_WHOLE), np.std(ACC_WHOLE)"
      ],
      "metadata": {
        "id": "aVgECVKmARQC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ACC_WHOLE, mean_acc, std_acc = train_svm_model(X, L)\n",
        "print(f'Accucracies = {ACC_WHOLE}')\n",
        "print(f'mean accuracy = {mean_acc}')\n",
        "print(f'standard deviation = {std_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2yc1B4FtCyu",
        "outputId": "64523a83-7c2e-4974-88ea-616988469fc2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm support vectors shape = (19, 4)\n",
            "svm support vectors = [3 9 7]\n",
            "Accucracies = [1.0, 1.0, 0.8666666666666667, 1.0, 0.8666666666666667]\n",
            "mean accuracy = 0.9466666666666667\n",
            "standard deviation = 0.06531972647421806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SFFS"
      ],
      "metadata": {
        "id": "XlBLUACJtcOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InPWN5G2ttax",
        "outputId": "d965bc18-ff56-4a34-e3d2-e19b9b9ca530"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear')\n",
        "sfsl = SFS(svm, k_features=4, forward=True, floating=True, verbose=2, scoring='accuracy', cv=5)\n",
        "sfsl.fit(X_train, L_train)\n",
        "results = sfsl.subsets_\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLGyhUFfth3s",
        "outputId": "1ddbedde-064f-40aa-cf66-141e62b75b2a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2024-03-19 10:01:55] Features: 1/4 -- score: 0.961904761904762\n",
            "[2024-03-19 10:01:55] Features: 2/4 -- score: 0.961904761904762\n",
            "[2024-03-19 10:01:55] Features: 3/4 -- score: 0.9523809523809523"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: {'feature_idx': (3,), 'cv_scores': array([0.95238095, 1.        , 1.        , 0.95238095, 0.9047619 ]), 'avg_score': 0.961904761904762, 'feature_names': ('3',)}, 2: {'feature_idx': (1, 3), 'cv_scores': array([0.95238095, 1.        , 1.        , 0.95238095, 0.9047619 ]), 'avg_score': 0.961904761904762, 'feature_names': ('1', '3')}, 3: {'feature_idx': (0, 2, 3), 'cv_scores': array([1.        , 0.95238095, 0.95238095, 0.95238095, 0.95238095]), 'avg_score': 0.9619047619047618, 'feature_names': ('0', '2', '3')}, 4: {'feature_idx': (0, 1, 2, 3), 'cv_scores': array([1.        , 0.9047619 , 0.95238095, 0.9047619 , 0.95238095]), 'avg_score': 0.9428571428571427, 'feature_names': ('0', '1', '2', '3')}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2024-03-19 10:01:55] Features: 3/4 -- score: 0.9619047619047618\n",
            "[2024-03-19 10:01:56] Features: 4/4 -- score: 0.9428571428571427"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features: 3/4 -- score: 0.9523809523809523{1: {'feature_idx': (3,), 'cv_scores': array([0.95238095, 1.        , 1.        , 0.95238095, 0.9047619 ]), 'avg_score': 0.961904761904762, 'feature_names': ('3',)}, 2: {'feature_idx': (1, 3), 'cv_scores': array([0.95238095, 1.        , 1.        , 0.95238095, 0.9047619 ]), 'avg_score': 0.961904761904762, 'feature_names': ('1', '3')}, 3: {'feature_idx': (0, 2, 3), 'cv_scores': array([1.        , 0.95238095, 0.95238095, 0.95238095, 0.95238095]), 'avg_score': 0.9619047619047618, 'feature_names': ('0', '2', '3')}, 4: {'feature_idx': (0, 1, 2, 3), 'cv_scores': array([1.        , 0.9047619 , 0.95238095, 0.9047619 , 0.95238095]), 'avg_score': 0.9428571428571427, 'feature_names': ('0', '1', '2', '3')}}\n",
        "X_train, X_test = X_train[:, [3]], X_test[:, [3]]"
      ],
      "metadata": {
        "id": "gRtwEvswuB64"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjF1XUeBuKiw",
        "outputId": "eaef52d6-c70c-433a-9c96-0faa2291cbe1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ACC_WHOLE, mean_acc, std_acc = train_svm_model(X, L)\n",
        "print(f'Accucracies = {ACC_WHOLE}')\n",
        "print(f'mean accuracy = {mean_acc}')\n",
        "print(f'standard deviation = {std_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3y51pCluLWy",
        "outputId": "4b6bf85d-b43f-49dd-8a88-95c26591dac6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm support vectors shape = (19, 4)\n",
            "svm support vectors = [3 9 7]\n",
            "Accucracies = [1.0, 1.0, 0.8666666666666667, 1.0, 0.8666666666666667]\n",
            "mean accuracy = 0.9466666666666667\n",
            "standard deviation = 0.06531972647421806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result of both linear svm without SFFS and with SFFS is the same (mean_accuracy = 0.9466666666666667). However, the SFFS has reduced features."
      ],
      "metadata": {
        "id": "UHDb4Cy9uZ60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How ML algorithms calculate feature importance?"
      ],
      "metadata": {
        "id": "91rmLpRQwnnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine learning models don't directly calculate a single \"score\" for each feature's importance. Instead, they employ various techniques that assess a feature's contribution to the model's predictions.\n",
        "\n",
        "1. Feature Coefficients (Linear Models):\n",
        "In linear models (like linear regression, logistic regression, and SVMs with linear kernels), the coefficients associated with each feature directly reflect their importance. A higher coefficient magnitude indicates a stronger influence on the model's output.\n",
        "\n",
        "2. Feature Importance Scores (Decision Trees and Random Forests):\n",
        "Decision trees and random forests measure feature importance by calculating how much a feature split contributes to reducing impurity (e.g., Gini impurity) at each node. The features that lead to the most significant reductions in impurity are considered more important.\n",
        "\n",
        "3. Permutation Importance (Any Model):\n",
        "This technique involves shuffling the values of a single feature and observing the change in the model's performance metric (e.g., accuracy, F1-score). A larger decrease in performance indicates that the shuffled feature played a significant role in the model's predictions. This method can be applied to any model type.\n",
        "\n",
        "4. Feature Selection Techniques:\n",
        "Algorithms like Sequential Feature Selection (SFS) and Recursive Feature Elimination (RFE) iteratively select or remove features based on their estimated importance. Their output can provide insights into which features contribute the most to model performance."
      ],
      "metadata": {
        "id": "fimEzTUturjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Backward Feature Selection (SBFS)"
      ],
      "metadata": {
        "id": "BembsS1Exo6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, L = load_iris(return_X_y=True)\n",
        "X_train, X_test, L_train, L_test = train_test_split(X, L, test_size=0.3)\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit_transform(X_train)\n",
        "sc.fit(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "3yIL49-Yy3V4",
        "outputId": "648d1b36-c9b8-41d5-92a9-18fba4c3a95e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear')\n",
        "sfsl = SFS(svm, k_features=1, forward=False, floating=True, verbose=2, scoring='accuracy', cv=5)\n",
        "sfsl.fit(X_train, L_train)\n",
        "results = sfsl.subsets_\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MhkjOIWy_wv",
        "outputId": "6bd45387-cebd-4cb1-891c-35bba7a199be"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{4: {'feature_idx': (0, 1, 2, 3), 'cv_scores': array([1.        , 1.        , 0.95238095, 1.        , 1.        ]), 'avg_score': 0.9904761904761905, 'feature_names': ('0', '1', '2', '3')}, 3: {'feature_idx': (0, 2, 3), 'cv_scores': array([1.        , 1.        , 1.        , 1.        , 0.95238095]), 'avg_score': 0.9904761904761905, 'feature_names': ('0', '2', '3')}, 2: {'feature_idx': (2, 3), 'cv_scores': array([1.        , 0.95238095, 1.        , 1.        , 0.95238095]), 'avg_score': 0.980952380952381, 'feature_names': ('2', '3')}, 1: {'feature_idx': (3,), 'cv_scores': array([0.95238095, 0.9047619 , 1.        , 0.95238095, 0.95238095]), 'avg_score': 0.9523809523809523, 'feature_names': ('3',)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2024-03-19 10:03:34] Features: 3/1 -- score: 0.9904761904761905\n",
            "[2024-03-19 10:03:34] Features: 2/1 -- score: 0.980952380952381\n",
            "[2024-03-19 10:03:34] Features: 1/1 -- score: 0.9523809523809523"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# {4: {'feature_idx': (0, 1, 2, 3), 'cv_scores': array([1.        , 1.        , 0.95238095, 1.        , 1.        ]), 'avg_score': 0.9904761904761905, 'feature_names': ('0', '1', '2', '3')}, 3: {'feature_idx': (0, 2, 3), 'cv_scores': array([1.        , 1.        , 1.        , 1.        , 0.95238095]), 'avg_score': 0.9904761904761905, 'feature_names': ('0', '2', '3')}, 2: {'feature_idx': (2, 3), 'cv_scores': array([1.        , 0.95238095, 1.        , 1.        , 0.95238095]), 'avg_score': 0.980952380952381, 'feature_names': ('2', '3')}, 1: {'feature_idx': (3,), 'cv_scores': array([0.95238095, 0.9047619 , 1.        , 0.95238095, 0.95238095]), 'avg_score': 0.9523809523809523, 'feature_names': ('3',)}}\n",
        "X_train, X_test = X_train[:, [0, 2, 3]], X_test[:, [0, 2, 3]]"
      ],
      "metadata": {
        "id": "SBL906oozKBf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ACC_WHOLE, mean_acc, std_acc = train_svm_model(X, L)\n",
        "print(f'Accucracies = {ACC_WHOLE}')\n",
        "print(f'mean accuracy = {mean_acc}')\n",
        "print(f'standard deviation = {std_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12mygyKbzFnr",
        "outputId": "2fd604e9-dccf-43d2-e8ae-261dea4cfd0e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm support vectors shape = (19, 4)\n",
            "svm support vectors = [3 9 7]\n",
            "Accucracies = [1.0, 1.0, 0.8666666666666667, 1.0, 0.8666666666666667]\n",
            "mean accuracy = 0.9466666666666667\n",
            "standard deviation = 0.06531972647421806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accurcy of SVM with SBFS and SFFS are the same on iris dataset"
      ],
      "metadata": {
        "id": "ZkYmwz-Dzjms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Are the results of SFFS and SBFS always the same?\n",
        "Reasons for Different Results:\n",
        "\n",
        "1. Search Direction:\n",
        "SFFS: Starts with an empty set and iteratively adds the most informative feature based on a chosen evaluation criterion.\n",
        "SBFS: Starts with all features and iteratively removes the least informative feature based on the same criterion.\n",
        "\n",
        "2. Path Dependence:\n",
        "The order in which features are added or removed can influence the final selection.\n",
        "If multiple features have similar importance, the initial choice can determine the subsequent selections.\n",
        "\n",
        "3. Evaluation Criterion:\n",
        "Both SFFS and SBFS rely on an evaluation criterion to assess feature importance. Different criteria (e.g., accuracy, F1-score) might prioritize features slightly differently."
      ],
      "metadata": {
        "id": "b5O6Ua3V0tP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other methods for feature selection:\n",
        "1. Filter methods (Correlation, Chi-aquare test, ANOVA, Information gain)\n",
        "2. Wrapper methods (Forward selection, backward elimination, stepwise selection)\n",
        "3. Embedded methods (LASSO, Elastic net, Ridge regression)"
      ],
      "metadata": {
        "id": "D3wdAWURzsB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stepwise feature selection\n",
        "* Stepwise regression is a regression technique used for feature selection, which aims to identify the subset of input features that are most relevant for predicting the output variable.\n",
        "* stepwise regression systematically selects input features based on their statistical significance and contribution to the model's performance.\n",
        "1. Forward Selection\n",
        "2. Backward Elimination\n",
        "3. Bidirectional Elimination: a combination of forward and backward selection, where the algorithm alternates between adding and removing features until no more changes can be made to improve the model performance.\n",
        "* To perform stepwise regression, the data must first be prepared by cleaning and preprocessing the data. This includes handling missing values, scaling the data, and encoding categorical variables.\n",
        "* Common indices used in stepwise regression include the Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), and modified R-squared.\n",
        "\n",
        "# Implementing forward stepwise regression\n",
        "1. Start with an empty set of features.\n",
        "2. Train the model using one feature at a time, starting with the most statistically significant feature.\n",
        "3. Evaluate the performance of the model at each step and keep track of the set of features that maximizes the performance.\n",
        "4. Continue adding features until no more features can be added without reducing the model's performance.\n",
        "\n",
        "# Implementing backward stepwise regression\n",
        "1. Start with the full set of features.\n",
        "2. Train the model using all the features.\n",
        "3. Evaluate the performance of the model at each step and keep track of the set of features that maximizes the performance.\n",
        "4. Remove the least statistically significant feature and repeat steps 2 and 3 until no more features can be removed without reducing the model's performance.\n",
        "\n",
        "# Implementing stepwise regression with both forward and backward selection\n",
        "1. Start with an empty or full set of features.\n",
        "2. Perform forward selection until no more features can be added without reducing the model's performance.\n",
        "3. Perform backward elimination until no more features can be removed without reducing the model's performance.\n",
        "4. Repeat steps 2 and 3 until no more changes can be made to improve the model performance.\n",
        "\n",
        "# Choosing the optimal number of features\n",
        "* To make this decision, we can use a method called \"recursive feature elimination\" (RFE), which involves repeatedly fitting the model with a decreasing number of features, and selecting the number of features that gives the best performance.\n",
        "\n",
        "https://dataaspirant.com/stepwise-regression/"
      ],
      "metadata": {
        "id": "mVnw5X4Lz87K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, L = load_iris(return_X_y=True)\n",
        "X_train, X_test, L_train, L_test = train_test_split(X, L, test_size=0.3)\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit_transform(X_train)\n",
        "sc.fit(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "gPu0CInw1rbo",
        "outputId": "f1fa59ce-cb2e-4bab-fe8e-5c706f8979bc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear')\n",
        "rfe = RFECV(estimator=svm, step=1, cv=5, scoring='accuracy')\n",
        "rfe.fit(X_train, L_train)\n",
        "print(rfe.support_)\n",
        "print(rfe.ranking_)\n",
        "print(rfe.n_features_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQqXaU_R1z75",
        "outputId": "a97c5253-eea1-4b9a-c229-a77f13515935"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True  True  True]\n",
            "[1 1 1 1]\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the 4 features in iris dataset are selected in RFECV method."
      ],
      "metadata": {
        "id": "jSCiMV7-6IbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ACC_WHOLE, mean_acc, std_acc = train_svm_model(X, L)\n",
        "print(f'Accucracies = {ACC_WHOLE}')\n",
        "print(f'mean accuracy = {mean_acc}')\n",
        "print(f'standard deviation = {std_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2nKfnNM5pXi",
        "outputId": "20425082-a0c1-465d-9d7c-256c9d684be0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm support vectors shape = (19, 4)\n",
            "svm support vectors = [3 9 7]\n",
            "Accucracies = [1.0, 1.0, 0.8666666666666667, 1.0, 0.8666666666666667]\n",
            "mean accuracy = 0.9466666666666667\n",
            "standard deviation = 0.06531972647421806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RFECV (Recursive Feature Elimination with Cross-Validation) method has the same accuracy as the SBFS and SFFS methods on iris dataset using kfold cross validation and SVM with linear kernel."
      ],
      "metadata": {
        "id": "auwKptDM559S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bi-directional Elimination\n",
        "It is the combination of both Backward Elimination and Forward Elimination.\n",
        "1. Select a significance level (SL) to stay and enter in the model. There would be two SLs, one used for backward elimination process and the other one for forward elimination process.\n",
        "2. Apply the next step of Forward selection. (Select one variable at a time and check for their p-values and select one feature whose p-value is less than SL)\n",
        "3. Apply all the steps of Backward Elimination. (This step will really start when we’ve selected at least two variables in step(ii) above.) We’ll check if we can get rid of any selected variable with step(ii).\n",
        "4. Repeat steps(ii) and (iii), until no new variables can be added or no old variable can be exit from the selected features and go to step(v).\n",
        "5. Stop\n",
        "\n",
        "https://medium.com/@abhishek.km23/methods-of-feature-selection-3b4c88f0e2d5"
      ],
      "metadata": {
        "id": "qWUGHwvn6Hij"
      }
    }
  ]
}