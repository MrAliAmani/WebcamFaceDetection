{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face_Detection using [https://realpython.com/face-recognition-with-python/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# for running on colab\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Your Environment and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir face_recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd face_recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Training Data and Train Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOG (histogram of oriented gradients) is a common technique for object detection. For this tutorial, you only need to remember that it works best with a CPU.\n",
    "CNN (convolutional neural network) is another technique for object detection. In contrast to a HOG, a CNN works better on a GPU, otherwise known as a video card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ENCODINGS_PATH = Path('output/encodings.pkl')\n",
    "BOUNDING_BOX_COLOR = 'blue'\n",
    "TEXT_COLOT = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description = 'Recognize faces in an image')\n",
    "parser.add_argument('--train', action='store_true', help='train on input data')\n",
    "parser.add_argument('--validate', action='store_true', help='validate trained model')\n",
    "parser.add_argument('--test', action='store_true', help='test the model with an unknown image')\n",
    "parser.add_argument(\n",
    "    '-m',\n",
    "    action='store',\n",
    "    default='hog',\n",
    "    choices=['hog', 'cnn'],\n",
    "    help='Which model to use for training: hog (CPU), cnn (GPU)'\n",
    ")\n",
    "parser.add_argument('-f', action='store', help='Path to an image with an unknown face')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('training').mkdir(exist_ok=True)\n",
    "Path('output').mkdir(exist_ok=True)\n",
    "Path('validation').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_known_faces(model: str = 'hog', encodings_location: Path = DEFAULT_ENCODINGS_PATH) -> None:\n",
    "    names = []\n",
    "    encodings = []\n",
    "    \n",
    "    for filepath in Path('training').glob('*/*'):\n",
    "        name  = filepath.parent.name\n",
    "        image = face_recognition.load_image_file(filepath)\n",
    "        \n",
    "        # bounding box\n",
    "        face_locations = face_recognition.face_locations(image, model = model)\n",
    "        face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "        \n",
    "        for encoding in face_encodings:\n",
    "            names.append(name)\n",
    "            encodings.append(encoding)\n",
    "            \n",
    "    name_encodings = {'names': names, 'encodings': encodings}\n",
    "    with encodings_location.open(mode='wb') as f:\n",
    "        pickle.dump(name_encodings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_known_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek', 'ben_afflek', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elon_musk', 'elton_john', 'elton_john', 'elton_john', 'elton_john', 'elton_john', 'elton_john', 'elton_john', 'elton_john', 'elton_john', 'elton_john', 'elton_john', 'elton_john', 'elton_john', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jerry_seinfeld', 'jobiden', 'jobiden', 'jobiden', 'jobiden', 'jobiden', 'jobiden', 'jobiden', 'jobiden', 'jobiden', 'jobiden', 'jobiden', 'jobiden', 'jobiden', 'jobiden', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'madonna', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling', 'mindy_kaling']\n"
     ]
    }
   ],
   "source": [
    "# with open('output/encodings.pkl', mode='rb') as f:\n",
    "#     loaded_encodings = pickle.load(f)\n",
    "# print(loaded_encodings['names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Recognize Unlabeled Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces(\n",
    "    image_location: str,\n",
    "    model: str = 'hog',\n",
    "    encodings_location: Path = DEFAULT_ENCODINGS_PATH\n",
    ") -> None:\n",
    "    with encodings_location.open(mode = 'rb') as f:\n",
    "        loaded_encodings = pickle.load(f)\n",
    "        \n",
    "    input_image = face_recognition.load_image_file(image_location)\n",
    "    \n",
    "    input_face_locations = face_recognition.face_locations(input_image, model=model)\n",
    "    input_face_encodings = face_recognition.face_encodings(input_image, input_face_locations)\n",
    "    \n",
    "    pillow_image = Image.fromarray(input_image)\n",
    "    draw = ImageDraw.Draw(pillow_image)\n",
    "    \n",
    "    for bounding_box, unknown_encoding in zip(\n",
    "        input_face_locations, input_face_encodings\n",
    "    ):\n",
    "        name = _recognize_face(unknown_encoding, loaded_encodings)\n",
    "        if not name:\n",
    "            name = 'Unknown'\n",
    "        # print(name, bounding_box)\n",
    "        _display_face(draw, bounding_box, name)\n",
    "        \n",
    "    del draw\n",
    "    pillow_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _recognize_face(unknown_encoding, loaded_encodings):\n",
    "    boolean_matches = face_recognition.compare_faces(\n",
    "        loaded_encodings['encodings'], unknown_encoding\n",
    "    )\n",
    "    votes = Counter(\n",
    "        name\n",
    "        for match, name in zip(boolean_matches, loaded_encodings['names'])\n",
    "    )\n",
    "    if votes:\n",
    "        return votes.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _display_face(draw, bounding_box, name):\n",
    "    top, right, bottom, left = bounding_box\n",
    "    draw.rectangle(((left, top), (right, bottom)), outline = BOUNDING_BOX_COLOR)\n",
    "    text_left, text_top, text_right, text_bottom = draw.textbbox(\n",
    "        (left, bottom), name\n",
    "    )\n",
    "    draw.rectangle(\n",
    "        ((text_left, text_top), (text_right, text_bottom)),\n",
    "        fill='blue',\n",
    "        outline='blue'\n",
    "    )\n",
    "    draw.text((text_left, text_top), name, fill='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_images\n",
    "# recognize_faces('amandeep.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognize_faces('BB12XCJF.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Validate Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model: str = 'hog'):\n",
    "    for filepath in Path('validation').rglob('*'):\n",
    "        if filepath.is_file():\n",
    "            recognize_faces(image_location = str(filepath.absolute()), model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Add Command-Line Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    if args.train:\n",
    "        encode_known_faces(args.m)\n",
    "    if args.validate:\n",
    "        validate(args.m)\n",
    "    if args.test:\n",
    "        recognize_faces(image_location=args.f, model=args.m)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Perform Face Recognition With Python"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
